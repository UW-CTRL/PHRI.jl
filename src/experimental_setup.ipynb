{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to store all of the setups of agents used in experiments in the case that files get corrupted or an updated version of Julia breaks the serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/repos/ProactiveHRI.jl`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "display_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Pkg\n",
    "using Serialization\n",
    "Pkg.activate(\"..\")\n",
    "include(\"dynamics.jl\")\n",
    "include(\"planner.jl\")\n",
    "include(\"planner_utils.jl\")\n",
    "include(\"utils.jl\")\n",
    "include(\"plotting.jl\")\n",
    "include(\"mpc.jl\")\n",
    "include(\"sim.jl\")\n",
    "include(\"experiments.jl\")\n",
    "include(\"velocity_obstacles.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionPlanner\n",
       "  ego_planner: AgentPlanner\n",
       "  other_planner: AgentPlanner\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ProactiveHRI robot \n",
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "# setting up ip\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "serialize(\"../experimental_setup/ProactiveHRI_robot.dat\", robot_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionPlanner\n",
       "  ego_planner: AgentPlanner\n",
       "  other_planner: AgentPlanner\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting up the human planner to be used for experiments (cooperative human)\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "# setting up the IP object to be serialized and saved for all trials\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving object\n",
    "serialize(\"../experimental_setup/cooperative_human_ip.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the human planner to be used for experiments (less cooperative human)\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([7.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 0.9\n",
    "collision_slack = 50.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 0.75\n",
    "inconvenience_ratio = 0.1\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "# setting up the IP object to be serialized and saved for all trials\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving object\n",
    "serialize(\"../experimental_setup/less-cooperative_human_ip.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the human planner to be used for experiments (ignorant/ideal planning human)\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([7.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 0.9\n",
    "collision_slack = 0.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 0.75\n",
    "inconvenience_ratio = 0.1\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "# setting up the IP object to be serialized and saved for all trials\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving object\n",
    "serialize(\"../experimental_setup/ignorant_human_ip.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the human planner to be used for experiments (overly aware human)\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([0.1; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.15\n",
    "collision_slack = 500.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.3\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.0\n",
    "collision_slack = 150.\n",
    "\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "# setting up the IP object to be serialized and saved for all trials\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving object\n",
    "serialize(\"../experimental_setup/overly_aware_human_ip.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal controller w/o markup\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.0\n",
    "collision_slack = 1000.\n",
    "trust_region_weight = 0.\n",
    "inconvenience_weights = [0.0; 0.0; 0.0]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 100.\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "# setting up ip\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving\n",
    "serialize(\"../experimental_setup/oc_no_ibr.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `DynamicallyExtendedUnicycle` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `DynamicallyExtendedUnicycle` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/repos/ProactiveHRI.jl/src/experimental_setup.ipynb:8"
     ]
    }
   ],
   "source": [
    "# low markup robot\n",
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 0.9\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "\n",
    "\n",
    "serialize(\"../experimental_setup/ProactiveHRI_low_markup.dat\", robot_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no markup robot\n",
    "# low markup robot\n",
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "\n",
    "\n",
    "serialize(\"../experimental_setup/ProactiveHRI_no_markup.dat\", robot_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high markup robot\n",
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.1\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([20.; 20.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "\n",
    "\n",
    "serialize(\"../experimental_setup/ProactiveHRI_high_markup.dat\", robot_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutral human\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.0\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1] \n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "serialize(\"../experimental_setup/neutral_human.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot model for sfm\n",
    "robot = DynamicallyExtendedUnicycle(dt, 2., [1., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot model for HJ \n",
    "robot = DynamicallyExtendedUnicycle(0.1, 2., [1., 0.5])\n",
    "robot_hps = PlannerHyperparameters(robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10100000111001001101111011000010110001101110100011010010111011001100101010010000101001001001001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seed for randomness\n",
    "ProactiveHRI_seed = 010100000111001001101111011000010110001101110100011010010111011001100101010010000101001001001001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[([10.; 0.; pi; 0.], [0.; 0.; pi; 0.])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
