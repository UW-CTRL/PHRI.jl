{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/repos/ProactiveHRI.jl`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pkg.instantiate()\n",
    "# Pkg.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reactive_velocity_obstacles (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"dynamics.jl\")\n",
    "include(\"planner.jl\")\n",
    "include(\"planner_utils.jl\")\n",
    "include(\"utils.jl\")\n",
    "include(\"plotting.jl\")\n",
    "include(\"mpc.jl\")\n",
    "include(\"sim.jl\")\n",
    "include(\"experiments.jl\")\n",
    "include(\"velocity_obstacles.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "velocity_max = 3.0\n",
    "# human = SingleIntegratorPolar2D(dt, velocity_max, [pi, 2.])\n",
    "human = Unicycle(dt, velocity_max, [1., 3.])\n",
    "\n",
    "time_horizon = 25\n",
    "# Q = zeros(Float64, human.state_dim, human.state_dim)\n",
    "# R = diagm([0.; 0.1]) \n",
    "# Qt = diagm([10.; 10.])\n",
    "Q = diagm([0.0; 0.0; 0.])\n",
    "R = diagm([1.0; 0.1]) \n",
    "Qt = diagm([10.; 10.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.01]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 3.0\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 3.])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_initial_state = [5.; 5.; -pi / 2.; 0.]\n",
    "robot_goal_state = [5.; -5.; -pi / 2; 0.]\n",
    "human_initial_state = [5.; -5.; pi / 2]\n",
    "human_goal_state = [5.; 5.; pi / 2]\n",
    "solver = \"ECOS\"\n",
    "\n",
    "ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "# \n",
    "# ip = InteractionPlanner(human_hps, \n",
    "#                         robot_hps,\n",
    "#                         human_initial_state,\n",
    "#                         robot_initial_state,\n",
    "#                         human_goal_state,\n",
    "#                         robot_goal_state,\n",
    "#                         solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a wall constraint to the planner\n",
    "wall_1 = Wall(\"x\", 0., 6.1, \"less\")\n",
    "wall_constraint(ip, wall_1, \"wall_1\")\n",
    "wall_2 = Wall(\"x\", 0.1, 3.2, \"greater\")\n",
    "wall_constraint(ip, wall_2, \"wall_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incon_problem, xs, us = @time solve(ip.ego_planner.incon, iterations=10, verbose=false, keep_history=false)\n",
    "incon_problem, xs, us = @time solve(ip.other_planner.incon, iterations=10, verbose=false, keep_history=false);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solve_solution(ip, walls=[wall_1, wall_2], pos_xlims=[-1, 11], pos_ylims=[-6, 6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterated Best Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time ibr(ip, 3, \"ego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solve_solution(ip, pos_xlims=[-1, 11], walls=nothing, pos_ylims=[-6, 6])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation(ip, pos_xlims=[-1, 11], pos_ylims=[-4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoidance_animation(ip, pos_xlims=[0, 10], pos_ylims=[-5, 5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPC Controller Simulation\n",
    "*At the moment it is a known issue that the sim breaks if the dynamics classes used are different between the different InteractionPlanner models, will be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"sim.jl\")\n",
    "include(\"mpc.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 0.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.01\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 0.\n",
    "inconvenience_weights = [1.; 1.; 0.1] \n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_path, robot_controls, human_path, human_controls, solve_times = simulate(robot_ip, human_ip, 75, ibr_iterations=2, leader=\"ego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation(robot_path, human_path, pos_xlims=[-1, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation(robot_path, human_path, pos_xlims=[-1, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(solve_times[1]) / 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findmax(solve_times[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot(robot_path[:,1], robot_path[:,2], xlims=[-1, 10], ylims=[-5, 5])\n",
    "plot!(plt, human_path[:,1], human_path[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation(robot_path, human_path, pos_xlims=[-1, 11], pos_ylims=[-2.5, 2.5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# human = SingleIntegratorPolar2D(dt, velocity_max, [pi, 2.])\n",
    "human = Unicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 50\n",
    "# Q = zeros(Float64, human.state_dim, human.state_dim)\n",
    "# R = diagm([0.; 0.1]) \n",
    "# Qt = diagm([10.; 10.])\n",
    "Q = diagm([0.0; 0.0; 0.])\n",
    "R = diagm([1.0; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.])\n",
    "markup = 0.8\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.01]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.13\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 3.])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi]\n",
    "human_goal_state = [0.; 0.; pi]\n",
    "solver = \"ECOS\"\n",
    "\n",
    "ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incon_problem, xs, us = @time solve(ip.ego_planner.incon, iterations=10, verbose=false, keep_history=false)\n",
    "incon_problem, xs, us = @time solve(ip.other_planner.incon, iterations=10, verbose=false, keep_history=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time saved_data_test, _, _, _, _ = ibr_save(ip, 5, \"ego\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"plotting.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example = plot_solve_solution(saved_data_test, scatter=false, show_speed=true, show_control=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_solve_solution(problem::SaveData, second_problem::SaveData,show_theta::Bool; pos_xlims=[-1,11], pos_ylims=[-6, 6], scatter=true::Bool, show_speed=true::Bool, show_control=true::Bool)\n",
    "\n",
    "    l = @layout [a b] \n",
    "    width=2000\n",
    "    height=800\n",
    "    alpha_plot = 0.7\n",
    "    linewidth = 2\n",
    "    markersize = 2\n",
    "    markersize_large = 7\n",
    "    ego_color = :blue\n",
    "    other_color = :red\n",
    "\n",
    "    global iterations = length(problem.previous_ips)\n",
    "\n",
    "    alpha_ratio = 1 / (iterations + 1)\n",
    "    N = problem.previous_ips[1].ego_planner.ideal.hps.time_horizon\n",
    "\n",
    "    ego_goal_state = problem.previous_ips[1].ego_planner.ideal.opt_params.goal_state\n",
    "    other_goal_state = problem.previous_ips[1].other_planner.ideal.opt_params.goal_state\n",
    "\n",
    "    ego_dynamics = problem.previous_ips[1].ego_planner.ideal.hps.dynamics       # use first ip arbitrarily, any iteration will give the same values for these entries\n",
    "    other_dynamics = problem.previous_ips[1].other_planner.ideal.hps.dynamics\n",
    "\n",
    "    global ego_ctrl_dim = 2\n",
    "    global other_ctrl_dim = 2\n",
    "\n",
    "    # plotting position trajectory\n",
    "\n",
    "    plot_traj = plot(size=(height, height), xlabel=\"x position\", ylabel=\"y position\", title=\"Position\", margin=10mm, ylims=pos_ylims, xlims=pos_xlims, aspect_ratio=:equal)\n",
    "    scatter!(ego_goal_state[1:1], ego_goal_state[2:2], marker=:star, markersize=markersize_large, color=ego_color, label=\"ego goal\")\n",
    "    scatter!(plot_traj, other_goal_state[1:1], other_goal_state[2:2], marker=:star, markersize=markersize_large, color=other_color, label=\"other goal\")\n",
    "\n",
    "    plot!(plot_traj, value.(problem.previous_ips[end].ego_planner.incon.model[:x])[:,1], value.(problem.previous_ips[end].ego_planner.incon.model[:x])[:,2], color=ego_color, linewidth=linewidth, label=\"Robot μ = 0.9\", alpha=alpha_plot)\n",
    "\n",
    "    plot!(plot_traj, value.(problem.previous_ips[end].other_planner.incon.model[:x])[:,1], value.(problem.previous_ips[end].other_planner.incon.model[:x])[:,2], color=other_color, linewidth=linewidth, label=\"Human μ = 0.9\", alpha=alpha_plot)\n",
    "\n",
    "\n",
    "    plot!(plot_traj, value.(second_problem.previous_ips[end].ego_planner.incon.model[:x])[:,1], value.(second_problem.previous_ips[end].ego_planner.incon.model[:x])[:,2], color=:purple, linewidth=linewidth, label=\"Robot μ = 1.1\", alpha=alpha_plot)\n",
    "\n",
    "    plot!(plot_traj, value.(second_problem.previous_ips[end].other_planner.incon.model[:x])[:,1], value.(second_problem.previous_ips[end].other_planner.incon.model[:x])[:,2], color=:green, linewidth=linewidth, label=\"Human μ = 1.1\", alpha=alpha_plot)\n",
    "\n",
    "    if scatter\n",
    "        scatter!(plot_traj, value.(problem.previous_ips[end].ego_planner.ideal.model[:x])[:,1], value.(problem.previous_ips[end].ego_planner.ideal.model[:x])[:,2], color=ego_color, linewidth=linewidth, label=\"\", alpha=alpha_plot)\n",
    "\n",
    "        scatter!(plot_traj, value.(problem.previous_ips[end].other_planner.ideal.model[:x])[:,1], value.(problem.previous_ips[end].other_planner.ideal.model[:x])[:,2], color=other_color, linewidth=linewidth, label=\"\", alpha=alpha_plot)\n",
    "\n",
    "        scatter!(plot_traj, value.(second_problem.previous_ips[end].ego_planner.ideal.model[:x])[:,1], value.(second_problem.previous_ips[end].ego_planner.ideal.model[:x])[:,2], color=ego_color, linewidth=linewidth, label=\"\", alpha=alpha_plot)\n",
    "\n",
    "        scatter!(plot_traj, value.(second_problem.previous_ips[end].other_planner.ideal.model[:x])[:,1], value.(second_problem.previous_ips[end].other_planner.ideal.model[:x])[:,2], color=other_color, linewidth=linewidth, label=\"\", alpha=alpha_plot)\n",
    "    end\n",
    "    # plotting speed/control\n",
    "\n",
    "    # speed parameters\n",
    "    max_speed = maximum([problem.previous_ips[1].ego_planner.ideal.hps.dynamics.velocity_max, problem.previous_ips[1].other_planner.ideal.hps.dynamics.velocity_max])\n",
    "    ego_max_speed = problem.previous_ips[1].ego_planner.ideal.hps.dynamics.velocity_max\n",
    "    other_max_speed = problem.previous_ips[1].other_planner.ideal.hps.dynamics.velocity_max\n",
    "\n",
    "    # control parameters\n",
    "    ego_ctrl_dim = problem.previous_ips[1].ego_planner.ideal.hps.dynamics.ctrl_dim\n",
    "    other_ctrl_dim = problem.previous_ips[1].other_planner.ideal.hps.dynamics.ctrl_dim\n",
    "\n",
    "    ego_max_ctrl = maximum(problem.previous_ips[1].ego_planner.ideal.hps.dynamics.control_max)\n",
    "    ego_min_ctrl = minimum(problem.previous_ips[1].ego_planner.ideal.hps.dynamics.control_min)\n",
    "    other_max_ctrl = maximum(problem.previous_ips[1].other_planner.ideal.hps.dynamics.control_max)\n",
    "    other_min_ctrl = minimum(problem.previous_ips[1].other_planner.ideal.hps.dynamics.control_min)\n",
    "\n",
    "    plot_theta = plot(size=(height, height), xlabel=\"time step\", ylabel=\"abs(Theta)\", title=\"Theta vs. time\", margin=10mm, legend=:bottomright)\n",
    "    plot_ctrl = plot(size=(height, height), xlabel=\"time step\", ylabel=\"input magnitude\", title=\"Control\", margin=10mm)\n",
    "\n",
    "    # angle plotting\n",
    "    robot_xs_mu_09 = vector_of_vectors_to_matrix(problem.previous_ips[iterations].ego_planner.incon.opt_params.previous_states)\n",
    "    human_xs_mu_09 = vector_of_vectors_to_matrix(problem.previous_ips[iterations].other_planner.incon.opt_params.previous_states)\n",
    "    robot_xs_mu_11 = vector_of_vectors_to_matrix(second_problem.previous_ips[iterations].ego_planner.incon.opt_params.previous_states)\n",
    "    human_xs_mu_11 = vector_of_vectors_to_matrix(second_problem.previous_ips[iterations].other_planner.incon.opt_params.previous_states)\n",
    "    plot!(plot_theta, robot_xs_mu_09[:,3:3], linewidth=2, label=\"Robot μ = 0.9\", color=ego_color)\n",
    "    plot!(plot_theta, human_xs_mu_09[:,3:3], linewidth=2, label=\"Human μ = 0.9\", color=other_color)\n",
    "    plot!(plot_theta, robot_xs_mu_11[:,3:3], linewidth=2, label=\"Robot μ = 1.1\", color=:magenta)\n",
    "    plot!(plot_theta, human_xs_mu_11[:,3:3], linewidth=2, label=\"Human μ = 1.1\", color=:green)\n",
    "\n",
    "        # ctrl plotting\n",
    "    plot!(plot_ctrl, 1:N, maximum([ego_max_ctrl, other_max_ctrl]) * ones(Float64, N), linestyle=:dash, linewith=linewidth,  color=:green, label=\"Control Limits\")\n",
    "    plot!(plot_ctrl, 1:N, minimum([ego_min_ctrl, other_min_ctrl]) * ones(Float64, N), linestyle=:dash, linewith=linewidth,  color=:green, label=\"\")   \n",
    "        # ego plot\n",
    "    for j in 1:ego_ctrl_dim\n",
    "        plot!(plot_ctrl, 1:N, vector_of_vectors_to_matrix(problem.previous_ips[iterations].ego_planner.incon.opt_params.previous_controls)[:, j], label=\"\", color=RGB(1 - (1 / ego_ctrl_dim) * j, 0., (1 / ego_ctrl_dim) * j), linewidth=linewidth, alpha=(i * alpha_ratio))\n",
    "        plot!(plot_ctrl, 1:N, vector_of_vectors_to_matrix(second_problem.previous_ips[iterations].ego_planner.incon.opt_params.previous_controls)[:, j], label=\"\", color=RGB(1 - (1 / ego_ctrl_dim) * j, 0., (1 / ego_ctrl_dim) * j), linewidth=linewidth, alpha=(i * alpha_ratio))\n",
    "    end \n",
    "        # other plot\n",
    "    for k in 1:other_ctrl_dim\n",
    "        plot!(plot_ctrl, 1:N, vector_of_vectors_to_matrix(problem.previous_ips[iterations].other_planner.incon.opt_params.previous_controls)[:, k], label=\"\", color=RGB((1 / other_ctrl_dim) * k, 1 - (1 / other_ctrl_dim) * k, 0.), linewidth=linewidth, alpha=(i * alpha_ratio))\n",
    "        plot!(plot_ctrl, 1:N, vector_of_vectors_to_matrix(second_problem.previous_ips[iterations].other_planner.incon.opt_params.previous_controls)[:, k], label=\"\", color=RGB((1 / other_ctrl_dim) * k, 1 - (1 / other_ctrl_dim) * k, 0.), linewidth=linewidth, alpha=(i * alpha_ratio))\n",
    "    end \n",
    "\n",
    "\n",
    "    slack_violation = Vector{Float64}(undef, iterations)\n",
    "\n",
    "    for i in 1:iterations\n",
    "        slack_violation[i] = value(problem.previous_ips[i].ego_planner.incon.model[:ϵ])\n",
    "    end\n",
    "\n",
    "    plot_slack_violation = plot(size=(height, height), xlabel=\"Iteration\", ylabel=\"ϵ (slack value)\", title=\"Slack (collision) Violation\", margin=10mm)\n",
    "\n",
    "    plot!(plot_slack_violation, 1:iterations, slack_violation, color=:black, label=\"Slack\")\n",
    "\n",
    "    # plotting inconvenience value over iterations\n",
    "\n",
    "    incon_budget = problem.previous_ips[1].ego_planner.incon.hps.inconvenience_ratio\n",
    "    inconvenience_ego = Vector{Float64}(undef, iterations)\n",
    "    inconvenience_other = Vector{Float64}(undef, iterations)\n",
    "\n",
    "    ideal_incon_ego = compute_convenience_value(ego_dynamics, matrix_to_vector_of_vectors(value.(problem.previous_ips[1].ego_planner.ideal.model[:x])), matrix_to_vector_of_vectors(value.(problem.previous_ips[1].ego_planner.ideal.model[:u])), ego_goal_state, problem.previous_ips[1].ego_planner.incon.hps.inconvenience_weights)\n",
    "\n",
    "    ideal_incon_other = compute_convenience_value(other_dynamics, matrix_to_vector_of_vectors(value.(problem.previous_ips[1].other_planner.ideal.model[:x])), matrix_to_vector_of_vectors(value.(problem.previous_ips[1].other_planner.ideal.model[:u])), other_goal_state, problem.previous_ips[1].other_planner.incon.hps.inconvenience_weights)\n",
    "\n",
    "    for i in 1:iterations\n",
    "        inconvenience_ego[i] = compute_convenience_value(ego_dynamics, problem.previous_ips[i].ego_planner.incon.opt_params.previous_states, problem.previous_ips[i].ego_planner.incon.opt_params.previous_controls, ego_goal_state, problem.previous_ips[1].ego_planner.incon.hps.inconvenience_weights)\n",
    "        \n",
    "        inconvenience_other[i] = compute_convenience_value(other_dynamics, problem.previous_ips[i].other_planner.incon.opt_params.previous_states, problem.previous_ips[i].other_planner.incon.opt_params.previous_controls, other_goal_state, problem.previous_ips[1].other_planner.incon.hps.inconvenience_weights)\n",
    "    end\n",
    "\n",
    "    inconvenience_ego ./= ideal_incon_ego\n",
    "    inconvenience_other ./= ideal_incon_other \n",
    "\n",
    "    plot_incon = plot(size=(height, height), xlabel=\"Iteration\", ylabel=\"Inconvenience\", title=\"Agent Inconvenience\", margin=10mm)\n",
    "    plot!(plot_incon, 1:iterations, ones(iterations), linestyle=:dash, linewith=linewidth, color=:green, label=\"Ideal Incon\")\n",
    "    plot!(plot_incon, 1:iterations, ones(iterations) .+ incon_budget, linestyle=:dash, linewith=linewidth, color=:black, label=\"Incon Budget\")\n",
    "    plot!(plot_incon, 1:iterations, inconvenience_ego, color=ego_color, linewidth=linewidth, label=\"Ego Incon\")\n",
    "    plot!(plot_incon, 1:iterations, inconvenience_other, color=other_color, linewidth=linewidth, label=\"Other Incon\")\n",
    "\n",
    "    plot(plot_traj, plot_theta, layout=l, size=(width, height))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sim Experimentation Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_params = PlannerParams(robot_ip.ego_planner.incon.hps, robot_ip.ego_planner.incon.opt_params, robot_ip.other_planner.incon.hps, robot_ip.other_planner.incon.opt_params)\n",
    "human_params = PlannerParams(human_ip.ego_planner.incon.hps, human_ip.ego_planner.incon.opt_params, human_ip.other_planner.incon.hps, human_ip.other_planner.incon.opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_params = IPSimParams(robot_params, human_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot_xs, robot_us, human_xs, human_us, solve_times = simulate(robot_ip, human_ip, 50, ibr_iterations=2, leader=\"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = SimData(sim_params, solve_times, robot_path, robot_controls, human_path, human_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solve_solution(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data.solve_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment in experiments\n",
    "#     set up problem. Assign hyperparameters. Cycle through hps for each experiment\n",
    "#     (markup, collision slack, trust region weights, incon weights, collision radius, incon ratio)\n",
    "#     for opt_param in opt_params\n",
    "#         assign new opt_params to the problem.\n",
    "#         (initial states, goal states)\n",
    "#         register the InteractionPlanner\n",
    "#         run simulation\n",
    "#         store data into dictionary w/ with key=run_number\n",
    "#         (store: hps, opt_params, and paths) -- enough data to recreate the problem and plot Base.load_path_setup_code\n",
    "#         delete interaction planner before cycling through the loop.\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressBars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the problem to be deep copied for experiments\n",
    "# this is for experimentation where each agent correctly assumes the policy of the oteher agent\n",
    "\n",
    "# setting up the robot planner\n",
    "solver = \"ECOS\"\n",
    "\n",
    "time_horizon = 25\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 1.]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "\n",
    "robot_ip = InteractionPlanner(robot_hps, \n",
    "                        human_hps,\n",
    "                        robot_initial_state,\n",
    "                        human_initial_state,\n",
    "                        robot_goal_state,\n",
    "                        human_goal_state,\n",
    "                        solver)\n",
    "                             \n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mohr's Circle-ish Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"experiments.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_states = mohrs_circle_states(test_human, [0., 0., 0., 0.], [10., 0., 0., 0.], pi / 6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_states = [([10., 0., pi, 0.], [0., 0., pi, 0.])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_test = simulation_sweep(robot_ip, human_ip, 50, robot_states, human_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_distance_to_goal(sim_test[\"Run 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_sim_data_plots(sim_test[\"Run 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_path_irregularity_index(sim_test[\"Run 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_control_effort(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_average_acceleration_per_segment(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_path_efficiency(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_path_irregularity_index(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_minimum_distance(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc = compute_time_to_collision(sim_data)\n",
    "# ttc[\"Time to collision\"]\n",
    "# plot(1:50, ttc[\"Time to collision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dθ_dt(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_θ(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_time(sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sweep_metrics = evaluate_sim(sim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sweep_metrics[\"Run 5\"].plots[\"Combined Plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(test_data_sweep_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(robot_ip, test_human_ip, 50, circular_experiment_states, [([10.; 0.; pi; 0.], [0.; 0.; pi; 0.])], \"experimental_setup/metrics_test.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proactiveHRI_robot_cooperative_human_circular = deserialize(\"../experimental_results/ProactiveHRI_robot_cooperative_human_circular.dat\")\n",
    "proactiveHRI_robot_cooperative_human_head_on = deserialize(\"../experimental_results/ProactiveHRI_robot_cooperative_human_head_on.dat\")\n",
    "SFM_robot_cooperative_human_circular = deserialize(\"../experimental_results/SFM_robot_cooperative_human_circular.dat\")\n",
    "SFM_robot_cooperative_human_head_on = deserialize(\"../experimental_results/SFM_robot_cooperative_human_head_on.dat\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phri_ego_pi = [proactiveHRI_robot_cooperative_human_head_on[\"Run $(i)\"].PI[\"ego PI\"] for i in 1:199]\n",
    "phri_other_pi = [proactiveHRI_robot_cooperative_human_head_on[\"Run $(i)\"].PI[\"other PI\"] for i in 1:199]\n",
    "sfm_ego_pi = [SFM_robot_cooperative_human_head_on[\"Run $(i)\"].PI[\"ego PI\"] for i in 1:199]\n",
    "sfm_other_pi = [SFM_robot_cooperative_human_head_on[\"Run $(i)\"].PI[\"other PI\"] for i in 1:199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(sfm_ego_pi), std(sfm_ego_pi), mean(sfm_other_pi), std(sfm_other_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(phri_ego_pi), std(phri_ego_pi), mean(phri_other_pi), std(phri_other_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(SFM_robot_cooperative_human_head_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(SFM_robot_cooperative_human_head_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Forces Sim w/ Dynamically Extended Unicycle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InteractionPlanner\n",
       "  ego_planner: AgentPlanner\n",
       "  other_planner: AgentPlanner\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting up the human planner to be used for experiments (cooperative human)\n",
    "solver = \"ECOS\"\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "human = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "time_horizon = 25\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.3]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "markup = 1.05\n",
    "collision_slack = 150.\n",
    "trust_region_weight = 5.\n",
    "inconvenience_weights = [1.; 1.; 0.1]\n",
    "collision_radius = 1.\n",
    "inconvenience_ratio = 0.2\n",
    "\n",
    "\n",
    "human_hps = PlannerHyperparameters(dynamics=human,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "\n",
    "\n",
    "dt = 0.1\n",
    "velocity_max = 1.5\n",
    "# robot = Unicycle(dt, velocity_max, [1.0, 2.])\n",
    "robot = DynamicallyExtendedUnicycle(dt, velocity_max, [1., 1.5])\n",
    "\n",
    "# time_horizon = 45\n",
    "Q = diagm([0.0; 0.0; 0.; 0.])\n",
    "R = diagm([1.; 0.0]) \n",
    "Qt = diagm([10.; 10.; 0.; 0.])\n",
    "\n",
    "robot_hps = PlannerHyperparameters(dynamics=robot,\n",
    "                             time_horizon=time_horizon,\n",
    "                             Q=Q,\n",
    "                             R=R,\n",
    "                             Qt=Qt,\n",
    "                             markup=markup,\n",
    "                             collision_slack=collision_slack,\n",
    "                             trust_region_weight=trust_region_weight,\n",
    "                             inconvenience_weights=inconvenience_weights,\n",
    "                             collision_radius=collision_radius,\n",
    "                             inconvenience_ratio=inconvenience_ratio)\n",
    "\n",
    "robot_initial_state = [0.; 0.; 0.; 0.]\n",
    "robot_goal_state = [10.; 0.; 0.; 0.]\n",
    "human_initial_state = [10.; 0.; pi; 0.]\n",
    "human_goal_state = [0.; 0.; pi; 0.]\n",
    "# setting up the IP object to be serialized and saved for all trials\n",
    "human_ip = InteractionPlanner(human_hps, \n",
    "                        robot_hps,\n",
    "                        human_initial_state,\n",
    "                        robot_initial_state,\n",
    "                        human_goal_state,\n",
    "                        robot_goal_state,\n",
    "                        solver)\n",
    "\n",
    "# saving object\n",
    "# serialize(\"../experimental_setup/cooperative_human_ip.dat\", human_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = DynamicallyExtendedUnicycle(dt, 2., [1., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = run_experiment(robot, human_ip, 50, circular_states, [([10.; 0.; pi; 0.], [0.; 0.; pi; 0.])], p=1., q=2., τ=2., ψ=pi/6, c=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HJ Reachability Experimentation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Interpolations\n",
    "using MAT\n",
    "include(\"velocity_obstacles.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simulation_sweep(ego_hps::PlannerHyperparameters, other_ip::InteractionPlanner, sim_horizon, ego_boundary_conditions::Vector{Tuple{Vector{Float64}, Vector{Float64}}}, other_boundary_conditions::Vector{Tuple{Vector{Float64}, Vector{Float64}}}; p=2., q=2., τ=2., ψ=pi/6, c=0.3)\n",
    "    runs = maximum([length(ego_boundary_conditions), length(other_boundary_conditions)])\n",
    "\n",
    "    ego_ego_hps = other_ip.other_planner.incon.hps\n",
    "    ego_other_hps = other_ip.ego_planner.incon.hps\n",
    "    other_ego_hps = other_ip.ego_planner.incon.hps\n",
    "    other_other_hps = other_ip.other_planner.incon.hps\n",
    "\n",
    "    # global HJIdata = matread(\"../hj_cache/DynamicallyExtendedUnicycle_VO_40_40_10_12_12.mat\")\n",
    "    global HJIdata = matread(\"../hj_cache/DynamicallyExtendedUnicycle_VO_50_50_10_20_20.mat\")\n",
    "\n",
    "    global V_mat = HJIdata[\"V\"]\n",
    "    global V_mat = [V_mat;;;V_mat[:,:,1:1,:,:]]\n",
    "    global grid_knots = tuple((x -> convert(Vector{Float32}, vec(x))).(HJIdata[\"grid_knots\"])...)\n",
    "    push!(grid_knots[3], -grid_knots[3][1])\n",
    "    global V = interpolate(Float32, Float32, grid_knots, V_mat, Gridded(Linear()));\n",
    "\n",
    "    if length(ego_boundary_conditions) == 1 \n",
    "        for i in 1:(runs - 1)\n",
    "            push!(ego_boundary_conditions, ego_boundary_conditions[1])\n",
    "        end\n",
    "    elseif length(other_boundary_conditions) == 1\n",
    "        for i in 1:(runs - 1)\n",
    "            push!(other_boundary_conditions, other_boundary_conditions[1])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(ego_boundary_conditions) != length(other_boundary_conditions)\n",
    "        throw(ArgumentError(\"length of 'ego_boundary_conditions' and 'other_boundary_conditions' must match\"))\n",
    "    end\n",
    "\n",
    "    runs_dict = Dict{String, SimData}()\n",
    "\n",
    "    for j in ProgressBar(1:runs)\n",
    "        sim_other_ip = InteractionPlanner(other_ego_hps, other_other_hps, other_boundary_conditions[j][1], ego_boundary_conditions[j][1], other_boundary_conditions[j][2], ego_boundary_conditions[j][2], \"ECOS\")\n",
    "\n",
    "        ego_params = PlannerParams(sim_other_ip.other_planner.incon.hps, sim_other_ip.other_planner.incon.opt_params, sim_other_ip.ego_planner.incon.hps, sim_other_ip.ego_planner.incon.opt_params)\n",
    "        other_params = PlannerParams(sim_other_ip.ego_planner.incon.hps, sim_other_ip.ego_planner.incon.opt_params, sim_other_ip.other_planner.incon.hps, sim_other_ip.other_planner.incon.opt_params)\n",
    "\n",
    "        sim_params = IPSimParams(ego_params, other_params)\n",
    "\n",
    "        ego_states, ego_controls, other_states, other_controls = simulate_hj(ego_hps, sim_other_ip, ego_boundary_conditions[j][1], ego_boundary_conditions[j][2], sim_horizon)\n",
    "\n",
    "        sim_data = SimData(sim_params, ([0.], nothing), ego_states, ego_controls, other_states, other_controls)\n",
    "\n",
    "        runs_dict[\"Run $(j)\"] = sim_data\n",
    "\n",
    "        # deleting variables\n",
    "        sim_ego_ip = nothing\n",
    "        sim_other_ip = nothing\n",
    "        ego_params = nothing\n",
    "        other_params = nothing\n",
    "        sim_params = nothing\n",
    "        ego_states = nothing\n",
    "        ego_controls = nothing\n",
    "        other_states = nothing\n",
    "        other_controls = nothing\n",
    "        sim_data = nothing\n",
    "    end\n",
    "\n",
    "    runs_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_robot = DynamicallyExtendedUnicycle(0.1, 2., [1., 0.5])\n",
    "test_robot_hps = PlannerHyperparameters(test_robot)\n",
    "robot_states = mohrs_circle_states(test_robot, [0., 0., 0., 0.], [10., 0., 0., 0.], pi / 6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hj_sim_sweep_test = simulation_sweep(test_robot_hps, human_ip, 50, robot_states, [([10.; 0.; pi; 0.], [0.; 0.; pi; 0.])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluate_sim(hj_sim_sweep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_data(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_sim_data_plots(hj_sim_sweep_test[\"Run 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_path_irregularity_index(hj_sim_sweep_test[\"Run 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Running Simulations\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0.0%┣                                               ┫ 0/12 [00:00<00:00, -0s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r8.3%┣███▋                                       ┫ 1/12 [00:09<Inf:Inf, InfGs/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r16.7%┣███████▊                                      ┫ 2/12 [00:16<02:40, 16s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r25.0%┣███████████▌                                  ┫ 3/12 [00:23<01:42, 11s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r33.3%┣███████████████▍                              ┫ 4/12 [00:29<01:18, 10s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r41.7%┣███████████████████▋                           ┫ 5/12 [00:36<01:02, 9s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r50.0%┣███████████████████████▌                       ┫ 6/12 [00:42<00:51, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r58.3%┣███████████████████████████▍                   ┫ 7/12 [00:49<00:41, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r66.7%┣███████████████████████████████▍               ┫ 8/12 [00:56<00:32, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r75.0%┣███████████████████████████████████▎           ┫ 9/12 [01:03<00:23, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r83.3%┣██████████████████████████████████████▍       ┫ 10/12 [01:09<00:15, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r91.7%┣██████████████████████████████████████████▏   ┫ 11/12 [01:16<00:08, 8s/it]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Evaluating Simulations\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100.0%┣█████████████████████████████████████████████┫ 12/12 [01:23<00:00, 8s/it]\n",
      "\u001b[1A\r100.0%┣█████████████████████████████████████████████┫ 12/12 [01:23<00:00, 8s/it]\n",
      "\r0.0%┣                                               ┫ 0/12 [00:00<00:00, -0s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r8.3%┣███▋                                       ┫ 1/12 [00:02<Inf:Inf, InfGs/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r16.7%┣███████▉                                       ┫ 2/12 [00:02<00:22, 2s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r25.0%┣███████████▊                                   ┫ 3/12 [00:02<00:11, 1s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r33.3%┣███████████████▊                               ┫ 4/12 [00:02<00:07, 1it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r41.7%┣███████████████████▋                           ┫ 5/12 [00:03<00:04, 2it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r50.0%┣███████████████████████▌                       ┫ 6/12 [00:03<00:03, 2it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r58.3%┣███████████████████████████▍                   ┫ 7/12 [00:03<00:02, 2it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r66.7%┣███████████████████████████████▍               ┫ 8/12 [00:03<00:02, 2it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r75.0%┣███████████████████████████████████▎           ┫ 9/12 [00:03<00:01, 3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r83.3%┣██████████████████████████████████████▍       ┫ 10/12 [00:03<00:01, 3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r91.7%┣██████████████████████████████████████████▏   ┫ 11/12 [00:03<00:00, 3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151Experiment finished in 87.76301097869873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1A\r100.0%┣█████████████████████████████████████████████┫ 12/12 [00:03<00:00, 3it/s]\n",
      "\u001b[1A\r100.0%┣█████████████████████████████████████████████┫ 12/12 [00:03<00:00, 3it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, SimMetrics} with 12 entries:\n",
       "  \"Run 4\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 10\" => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 1\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 11\" => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 6\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 12\" => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 2\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 9\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 5\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 8\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 7\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…\n",
       "  \"Run 3\"  => SimMetrics(SimData(IPSimParams(PlannerParams(PlannerHyperparamete…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_test = run_experiment(test_robot_hps, human_ip, 50, robot_states, [([10.; 0.; pi; 0.], [0.; 0.; pi; 0.])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimData(IPSimParams(PlannerParams(PlannerHyperparameters{Float64}\n",
       "  dynamics: DynamicallyExtendedUnicycle{Float64}\n",
       "  time_horizon: Int64 51\n",
       "  Q: Array{Float64}((4, 4)) [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  R: Array{Float64}((2, 2)) [1.0 0.0; 0.0 0.0]\n",
       "  Qt: Array{Float64}((4, 4)) [10.0 0.0 0.0 0.0; 0.0 10.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  markup: Float64 1.05\n",
       "  collision_slack: Float64 150.0\n",
       "  collision_markup: Float64 0.98\n",
       "  trust_region_weight: Float64 5.0\n",
       "  inconvenience_weights: Array{Float64}((3,)) [1.0, 1.0, 0.1]\n",
       "  collision_radius: Float64 1.0\n",
       "  inconvenience_ratio: Float64 0.2\n",
       ", PlannerOptimizerParams{Float64}\n",
       "  As: Array{Matrix{Float64}}((25,))\n",
       "  Bs: Array{Matrix{Float64}}((25,))\n",
       "  Cs: Array{Vector{Float64}}((25,))\n",
       "  Gs: Array{Vector{Float64}}((26,))\n",
       "  Hs: Array{Float64}((26,)) [7.946747608506369, 6.8816909162343505, 5.810974632063962, 4.733899629336222, 3.648296748807564, 2.5639512163727725, 1.490382642090832, 0.42384927924120147, -0.6387717712081851, -1.6988059683843282  …  -9.568388872884722, -10.778788347797583, -12.017497389141385, -13.287391030259151, -14.591098495281129, -15.930968613369206, -17.308925965476313, -18.726612009375927, -20.185529296430914, -21.69426465202825]\n",
       "  inconvenience_budget: Float64 4.096495146606284\n",
       "  initial_state: Array{Float64}((4,)) [1.8346099727399592, -0.1828071438412934, 0.02793257653542353, 0.30811020641237163]\n",
       "  goal_state: Array{Float64}((4,)) [10.0, 0.0, 0.0, 0.0]\n",
       "  previous_states: Array{Vector{Float64}}((26,))\n",
       "  previous_controls: Array{Vector{Float64}}((25,))\n",
       "  other_positions: Array{Vector{Float64}}((26,))\n",
       "  solver: String \"ECOS\"\n",
       ", PlannerHyperparameters{Float64}\n",
       "  dynamics: DynamicallyExtendedUnicycle{Float64}\n",
       "  time_horizon: Int64 51\n",
       "  Q: Array{Float64}((4, 4)) [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  R: Array{Float64}((2, 2)) [1.0 0.0; 0.0 0.3]\n",
       "  Qt: Array{Float64}((4, 4)) [10.0 0.0 0.0 0.0; 0.0 10.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  markup: Float64 1.05\n",
       "  collision_slack: Float64 150.0\n",
       "  collision_markup: Float64 0.98\n",
       "  trust_region_weight: Float64 5.0\n",
       "  inconvenience_weights: Array{Float64}((3,)) [1.0, 1.0, 0.1]\n",
       "  collision_radius: Float64 1.0\n",
       "  inconvenience_ratio: Float64 0.2\n",
       ", PlannerOptimizerParams{Float64}\n",
       "  As: Array{Matrix{Float64}}((25,))\n",
       "  Bs: Array{Matrix{Float64}}((25,))\n",
       "  Cs: Array{Vector{Float64}}((25,))\n",
       "  Gs: Array{Vector{Float64}}((26,))\n",
       "  Hs: Array{Float64}((26,)) [-9.946747607365822, -8.883921958866964, -7.818867245599727, -6.7495729864501355, -5.673270690907681, -4.601801616841077, -3.546641354843861, -2.5033273713224795, -1.467789801187962, -0.43768018476406634  …  7.227747094709223, 8.414006796814387, 9.630330565806421, 10.879693231381081, 12.164749881011517, 13.48778611955483, 14.850565176055568, 16.25444975345366, 17.700449487711616, 19.19670879883501]\n",
       "  inconvenience_budget: Float64 1.2873349409453188\n",
       "  initial_state: Array{Float64}((4,)) [3.47073290211307, 0.5476978490177528, 2.9087330221534193, 1.4611134384631146]\n",
       "  goal_state: Array{Float64}((4,)) [0.0, 0.0, 3.141592653589793, 0.0]\n",
       "  previous_states: Array{Vector{Float64}}((26,))\n",
       "  previous_controls: Array{Vector{Float64}}((25,))\n",
       "  other_positions: Array{Vector{Float64}}((26,))\n",
       "  solver: String \"ECOS\"\n",
       "), PlannerParams(PlannerHyperparameters{Float64}\n",
       "  dynamics: DynamicallyExtendedUnicycle{Float64}\n",
       "  time_horizon: Int64 51\n",
       "  Q: Array{Float64}((4, 4)) [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  R: Array{Float64}((2, 2)) [1.0 0.0; 0.0 0.3]\n",
       "  Qt: Array{Float64}((4, 4)) [10.0 0.0 0.0 0.0; 0.0 10.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  markup: Float64 1.05\n",
       "  collision_slack: Float64 150.0\n",
       "  collision_markup: Float64 0.98\n",
       "  trust_region_weight: Float64 5.0\n",
       "  inconvenience_weights: Array{Float64}((3,)) [1.0, 1.0, 0.1]\n",
       "  collision_radius: Float64 1.0\n",
       "  inconvenience_ratio: Float64 0.2\n",
       ", PlannerOptimizerParams{Float64}\n",
       "  As: Array{Matrix{Float64}}((25,))\n",
       "  Bs: Array{Matrix{Float64}}((25,))\n",
       "  Cs: Array{Vector{Float64}}((25,))\n",
       "  Gs: Array{Vector{Float64}}((26,))\n",
       "  Hs: Array{Float64}((26,)) [-9.946747607365822, -8.883921958866964, -7.818867245599727, -6.7495729864501355, -5.673270690907681, -4.601801616841077, -3.546641354843861, -2.5033273713224795, -1.467789801187962, -0.43768018476406634  …  7.227747094709223, 8.414006796814387, 9.630330565806421, 10.879693231381081, 12.164749881011517, 13.48778611955483, 14.850565176055568, 16.25444975345366, 17.700449487711616, 19.19670879883501]\n",
       "  inconvenience_budget: Float64 1.2873349409453188\n",
       "  initial_state: Array{Float64}((4,)) [3.47073290211307, 0.5476978490177528, 2.9087330221534193, 1.4611134384631146]\n",
       "  goal_state: Array{Float64}((4,)) [0.0, 0.0, 3.141592653589793, 0.0]\n",
       "  previous_states: Array{Vector{Float64}}((26,))\n",
       "  previous_controls: Array{Vector{Float64}}((25,))\n",
       "  other_positions: Array{Vector{Float64}}((26,))\n",
       "  solver: String \"ECOS\"\n",
       ", PlannerHyperparameters{Float64}\n",
       "  dynamics: DynamicallyExtendedUnicycle{Float64}\n",
       "  time_horizon: Int64 51\n",
       "  Q: Array{Float64}((4, 4)) [0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  R: Array{Float64}((2, 2)) [1.0 0.0; 0.0 0.0]\n",
       "  Qt: Array{Float64}((4, 4)) [10.0 0.0 0.0 0.0; 0.0 10.0 0.0 0.0; 0.0 0.0 0.0 0.0; 0.0 0.0 0.0 0.0]\n",
       "  markup: Float64 1.05\n",
       "  collision_slack: Float64 150.0\n",
       "  collision_markup: Float64 0.98\n",
       "  trust_region_weight: Float64 5.0\n",
       "  inconvenience_weights: Array{Float64}((3,)) [1.0, 1.0, 0.1]\n",
       "  collision_radius: Float64 1.0\n",
       "  inconvenience_ratio: Float64 0.2\n",
       ", PlannerOptimizerParams{Float64}\n",
       "  As: Array{Matrix{Float64}}((25,))\n",
       "  Bs: Array{Matrix{Float64}}((25,))\n",
       "  Cs: Array{Vector{Float64}}((25,))\n",
       "  Gs: Array{Vector{Float64}}((26,))\n",
       "  Hs: Array{Float64}((26,)) [7.946747608506369, 6.8816909162343505, 5.810974632063962, 4.733899629336222, 3.648296748807564, 2.5639512163727725, 1.490382642090832, 0.42384927924120147, -0.6387717712081851, -1.6988059683843282  …  -9.568388872884722, -10.778788347797583, -12.017497389141385, -13.287391030259151, -14.591098495281129, -15.930968613369206, -17.308925965476313, -18.726612009375927, -20.185529296430914, -21.69426465202825]\n",
       "  inconvenience_budget: Float64 4.096495146606284\n",
       "  initial_state: Array{Float64}((4,)) [1.8346099727399592, -0.1828071438412934, 0.02793257653542353, 0.30811020641237163]\n",
       "  goal_state: Array{Float64}((4,)) [10.0, 0.0, 0.0, 0.0]\n",
       "  previous_states: Array{Vector{Float64}}((26,))\n",
       "  previous_controls: Array{Vector{Float64}}((25,))\n",
       "  other_positions: Array{Vector{Float64}}((26,))\n",
       "  solver: String \"ECOS\"\n",
       ")), ([0.0], nothing), [0.0 0.0 0.0 0.0; 0.0025000000000000005 0.0 0.0 0.05; … ; 1.8346099727399592 -0.1828071438412934 0.02793257653542353 0.30811020641237163; 1.8649738087963785 -0.18190920624149357 0.03121100165491452 0.29943227224639557], [0.0 0.5; 0.0 0.4797215188353386; … ; 0.03891682714673439 -0.0832905132049171; 0.03278425119490991 -0.08677934165976064], [10.0 0.0 3.141592653589793 0.0; 9.991945187773569 9.864300010833262e-19 3.1415840340984826 0.16109624452864565; … ; 3.47073290211307 0.5476978490177528 2.9087330221534193 1.4611134384631146; 3.3293906756435643 0.5810032015698886 2.9116285961124584 1.443151440992062], [-8.619491310329311e-5 1.6109624452864564; 0.07127865484602407 1.4381005146759533; … ; 0.011552493096686737 -0.15271323916256171; 0.02895573959039241 -0.17961997471052527])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_test[\"Run 1\"].sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GtkLabelLeaf(name=\"\", parent, width-request=-1, height-request=-1, visible=TRUE, sensitive=TRUE, app-paintable=FALSE, can-focus=FALSE, has-focus=FALSE, is-focus=FALSE, focus-on-click=TRUE, can-default=FALSE, has-default=FALSE, receives-default=FALSE, composite-child=FALSE, style, events=0, no-show-all=FALSE, has-tooltip=FALSE, tooltip-markup=NULL, tooltip-text=NULL, window, opacity=1.000000, double-buffered, halign=GTK_ALIGN_FILL, valign=GTK_ALIGN_FILL, margin-left, margin-right, margin-start=0, margin-end=0, margin-top=0, margin-bottom=100, margin=100, hexpand=FALSE, vexpand=FALSE, hexpand-set=FALSE, vexpand-set=TRUE, expand=FALSE, scale-factor=1, xpad, ypad, label=\"<b><u>Sim 12 Metrics</u></b>\n",
       "<b> </b> \n",
       "<b>Ego Average Acceleration = </b>0.06195\n",
       "<b>Other Average Acceleration = </b>0.2926\n",
       "<b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b>\n",
       "<b>Ego PI = </b>4.676\n",
       "<b>Other PI = </b>5.814\n",
       "<b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b>\n",
       "<b>Ego PE = </b>0.2834\n",
       "<b>Other PE = </b>1.003\n",
       "<b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b>\n",
       "<b>Minimum Distance = </b>1.633\n",
       "<b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b><b>-</b>\n",
       "<b>Max Solve Time: </b>0.0 s\n",
       "<b>Average Solve Time: </b>0.0 s\n",
       "<b>Planning Deadline Overruns: </b>0\", attributes, use-markup=TRUE, use-underline=FALSE, justify=GTK_JUSTIFY_LEFT, pattern, wrap=FALSE, wrap-mode=PANGO_WRAP_WORD, selectable=FALSE, mnemonic-keyval=16777215, mnemonic-widget, cursor-position=0, selection-bound=0, ellipsize=PANGO_ELLIPSIZE_NONE, width-chars=-1, single-line-mode=FALSE, angle=0.000000, max-width-chars=-1, track-visited-links=TRUE, lines=-1, xalign=0.500000, yalign=0.500000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_data(metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_distance_to_goal(sim_data)\n",
    "    dt = sim_data.sim_params.ego_planner_params.hps.dynamics.dt\n",
    "    sim_horizon = length(sim_data.ego_states[:, 1])\n",
    "\n",
    "    ego_dyn = sim_data.sim_params.ego_planner_params.hps.dynamics\n",
    "    ego_xs = sim_data.ego_states\n",
    "    ego_us = sim_data.ego_controls\n",
    "    ego_goal = sim_data.sim_params.ego_planner_params.opt_params.goal_state\n",
    "\n",
    "    other_dyn = sim_data.sim_params.other_planner_params.hps.dynamics\n",
    "    other_xs = sim_data.other_states\n",
    "    other_us = sim_data.other_controls\n",
    "    other_goal = sim_data.sim_params.other_planner_params.opt_params.goal_state\n",
    "\n",
    "    ego_dist = norm(get_position(ego_dyn, ego_goal - ego_xs[end, :]))\n",
    "    other_dist = norm(get_position(other_dyn, other_goal - other_xs[end, :]))\n",
    "\n",
    "    Dict(\"ego dist to goal\" => ego_dist, \"other dist to goal\" => other_dist)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
